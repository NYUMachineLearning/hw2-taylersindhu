---
title: HW2
author: "Tayler Sindhu"
date: "Fall 2019"
output:
  html_document:
    df_print: paged
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = T)
```

# Regression

```{r, include=FALSE}
library(caret)
library(MASS)
library(ggplot2)
library(dplyr)
library(ggfortify)


#Mauna Loa CO2 concentrations
data(airquality)
airquality
```


1. Split data into training and test set (75% in train set, 25% in test set)

```{r}
# Set seed so random sampling is reproducible
set.seed(486)

# take a random sample of 75% of rows idices
train <- sample(nrow(airquality), nrow(airquality)*.75)
# subsets the dataframe by the rows selected in the sample function
train_regression <- airquality[sort(train),]
test_regression = airquality[sort(-train),]
```


### Linear Regression

* Assumes a linear relationship. 
* Independent variables should not be correlated (no mulitcollinearity)
* The number of observations should be greater than the number of independent variables.


$$RSS=\sum(y_i - \hat{y_i})^2$$
We will predict the response of the Temperature based on Wind. 

This is the data we will fit a linear model to. 
```{r}
 ggplot(data = train_regression) +
   geom_point(aes(x=Wind, y=Temp)) +
   theme_bw()
```

2. Create and fit a linear model to predict Temperature from Wind using the training set
```{r}
#help(train)
set.seed(40)
linear_regression <- train(Temp ~ Wind, data= train_regression, method = "lm", na.action = na.omit)
```


3. Vizualize how your model performed on the train data by plotting the regression line on top of the train data points. 
```{r}

# plotted predicted values of train data

predicted_values_train = predict(linear_regression, train_regression)

 ggplot() +
   geom_point(data = train_regression, aes(x=Wind, y=Temp)) +
   geom_line(data = train_regression, aes(x=Wind, y=predicted_values_train))+
   theme_bw()
```


4. Explore how the model performs on the test data. For Linear Regression:

* The residuals should be close to zero.
* There should be equal variance around the regression line (homoscedasticity).
* Residuals should be normally distributed.
* Independent variables and residuals should not be correlated.

4 a) See how the model performs on the test data
```{r}
#help(predict)
linear_predict <- sort(predict(linear_regression, newdata=test_regression))
linear_predict
```

4 b) Look at the residuals. Are they close to zero?
```{r}
#look at the median residual value. Close to zero is best
#help(summary)
summary(linear_regression)
```
**The median residual value is 1.7, and appears relatively centered around zero.**

4 c) Plot predicted temperature vs observed temperature. A strong model should show a strong correlation
```{r}
# on test dataset?
 ggplot() +
   geom_point(data = test_regression, aes(x=linear_predict, y=Temp)) +
   theme_bw() +
  xlab("Predicted Temperature") +
  ylab("Observed Temperature") + 
  ggtitle("Predicted Temperature vs. Observed Temperature") +
  theme(plot.title = element_text(hjust = 0.5))
```

4 d) Visualize the predicted values in relation to the real data points. Look for homoscedasticity
```{r}
# Extract coefficients from the model
coef(linear_regression$finalModel)

# plot the regression line on the predicted values
# plot the original test values

 ggplot(data=test_regression, aes(x=Wind, y=linear_predict, col="Predicted")) +
   geom_point() +
   geom_point(aes(x=Wind, y=Temp, color="Observed")) +
   geom_abline(intercept = 89.010, slope = -1.174) +
   geom_segment(aes(yend=Temp, xend= Wind)) +
   theme_bw()  +
   xlab("Wind") +
   ylab("Temperature") + 
   ggtitle("Temperature vs. Wind") +
   theme(plot.title = element_text(hjust = 0.5))
  
```

4 e) Residuals should be normally distributed. Plot the density of the residuals
```{r}
#residuals_lin <- residuals(linear_regression)
#ggplot(data=residvpredict) +
#  geom_density(aes(residual))

residuals_lin <- residuals(linear_regression)

# Makes dataframe of training data and residuals of training data
residvpredict <- data.frame(predicted_values_train, residuals_lin)

ggplot(data=residvpredict) +
  geom_density(aes(x=residuals_lin)) +
  xlab("Residuals")

```


4 f) Independent variables and residuals should not be correlated
```{r}
cor.test(train_regression$Wind, resid(linear_regression))
```


### Linear Regression with Regularization

5. Create a linear model using L1 or L2 regularization to predict Temperature from Wind and Month variables. Plot your predicted values and the real Y values on the same plot. 
```{r}
# Create model
set.seed(40)
lasso_mod <- train(Temp ~ Wind + Month, data= train_regression, method = "lasso")

pred_mod_train = predict(lasso_mod, train_regression)

 ggplot() +
   geom_point(data = train_regression, aes(x=pred_mod_train, y=Temp)) +
   theme_bw() +
   xlab("Predicted Temperature") +
   ylab("Observed Temperature") + 
   ggtitle("Predicted Temperature vs. Observed Temperature") +
   theme(plot.title = element_text(hjust = 0.5))
```



